{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nltk: Stop Words_Stemming_",
      "provenance": [],
      "authorship_tag": "ABX9TyPbbHi9jwn0ACevx4xT1djw"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBI2nY8aDe1O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords \n",
        "from nltk.tokenize import word_tokenize"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wi8FGz7CGlPm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "e922fdb3-8b0f-4cac-c6c0-a8e471bdcda0"
      },
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhoLGLf_Fx_s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cbc3684f-bd86-4d3f-d586-5f9ffd684930"
      },
      "source": [
        "example_text = \"If everyone would stop talking about it\"\n",
        "words = set(word_tokenize(example_text, language='english', ))\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "filter = [w for w in words if not w in stop_words]\n",
        "print(filter)\n",
        "\n",
        "##for w in words:\n",
        "##  if w not in stop_words:\n",
        "  ####print(filter)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['stop', 'If', 'talking', 'would', 'everyone']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NL_QQrpZGhOw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##PART - 3 : STEMMING IN NLTK\n",
        "##Stemming refers to the process of removing the suffixes and using the stem like rid for riding or ridden or ride \n",
        "##This is done in order to reduce the dataset so that they dont get meanings defined and can cause redundancy. Stemming removes that\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZ_eks9LJO5g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.stem import PorterStemmer \n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiXEaop-LbPp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ps = PorterStemmer()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3CkbgolLdoN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "0cf734be-e326-413b-b778-9665051585e2"
      },
      "source": [
        "example = [\"python\",\"pythoner\",\"pythoning\",\"pythonly\",\"pythoned\"]\n",
        "\n",
        "for w in example:\n",
        "  print(ps.stem(w))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "python\n",
            "python\n",
            "python\n",
            "pythonli\n",
            "python\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vlz1GG7JLf8Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "outputId": "81b626da-1909-4579-fef3-5ea149a3d4fd"
      },
      "source": [
        "eg = \"I saw a python last night, while I was pythoning and solving a situation pythonly with another pythoner, when it was just pythoned\"\n",
        "words = word_tokenize(eg, language=\"english\")\n",
        "for w in words:\n",
        "  print(ps.stem(w))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I\n",
            "saw\n",
            "a\n",
            "python\n",
            "last\n",
            "night\n",
            ",\n",
            "while\n",
            "I\n",
            "wa\n",
            "python\n",
            "and\n",
            "solv\n",
            "a\n",
            "situat\n",
            "pythonli\n",
            "with\n",
            "anoth\n",
            "python\n",
            ",\n",
            "when\n",
            "it\n",
            "wa\n",
            "just\n",
            "python\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azXxYjogMfa9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}